% -*- root: Document.tex -*-

\chapter{State-of-the-Art}
\label{chap:soa}

Spark~\cite{Zaharia:2013:DSF:2517349.2522737} has recently gained a lot of traction as prominent solution to implement efficient stream processing.
It leverages Resilient Distributed Datasets (RDD) to provide a uniform view on the data to process.
Despite its popularity, Spark only handles unencrypted data and hence does not offer security guarantees.
Recent proposals~\cite{7840754} study possible software solutions to overcome this limitation.

Several big industrial players introduced their own stream processing solutions.
These systems are mainly used to ingest massive amounts of data and efficiently perform (real-time) analytics.
Twitter's Heron~\cite{Kulkarni:2015:THS:2723372.2742788}, and Google's Cloud DataFlow~\cite{Akidau:2015:DMP:2824032.2824076} are two prominent examples.
These systems are typically deployed on the provider's premises and are not offered \emph{as a service} to end-users.

A few dedicated solutions exist today for distributed stream processing using reactive programming.
For instance, \textsc{Reactive Kafka}~\cite{reactivekafka} allows stream processing atop of Apache \textsc{Kafka}~\cite{apachekafka,kreps2011kafka}.
These solutions do not, however, support secure execution in a trusted execution environment.

More recently, some open-source middleware frameworks (\textit{e.g.}, Apache \textsc{Spark}~\cite{apachesparkstreaming}, Apache \textsc{Storm}~\cite{apachestorm}, \textsc{Infinispan}~\cite{infinispan}) introduced APIs to allow developers to quickly set up and deploy stream processing infrastructures.
These systems rely on the \emph{Java} virtual machine (JVM)~\cite{lindholm2014java}.
However, SGX currently imposes a hard memory limit of 128\,MB to the enclaved code and data, at the cost of expensive encrypted memory paging mechanisms and serious performance overheads~\cite{pires_scbr:2016,brenner_securekeeper:_2016} when this limit is crossed.
Moreover, executing a fully-functional JVM inside an SGX enclave would currently involve significant re-engineering efforts.

\textsc{DEFCon}~\cite{Migliavacca:2010:DHE} relies also on the JVM.
This event processing system focuses on security by enforcing constraints on event flows between processing units.
The event flow control is enforced using application-level virtualisation to separate processing units in a \textit{ad-hoc} JVM.

A few recent contributions tackle privacy-preserving data processing, particularly in a MapReduce scenario.
This is the case of Airavat~\cite{Roy:2010:ASP:1855711.1855731} and \textsc{Gupt}~\cite{Mohan:2012:GPP:2213836.2213876}.
These systems leverage differential-privacy techniques~\cite{dwork2006calibrating} and can face a different threat model than the one supported by SGX and hence by \SS.
In particular, when deploying such systems on a public infrastructure, one needs to trust the cloud provider.
Our system greatly reduces the trust boundaries, and only requires trust of Intel{\textregistered} and their SGX implementation.

Some authors contest that public clouds may be secure enough some parts of an application.
They propose to split the jobs, running only the critical parts in private clouds.
A privacy-aware framework on hybrid clouds~\cite{xu2015framework} has been proposed to work on tagged data, at different granularity levels.
A MapReduce preprocessor splits data into private and public clouds according to their sensitivity.
Sedic~\cite{zhang2011sedic} does not offer the same tagging granularity, but proposes to automatically modify reducers to optimize the data transfers in a hybrid cloud.
These solutions require splitting application and data in two parts (sensitive and not) and impose higher latencies due to data transfers between two different clouds.
Yet, they cannot offer better security guarantees that the software stack itself offers, be it public or private.

MrCrypt~\cite{tetali2013mrcrypt} proposes using homomorphic encryption instead of trusted elements.
Through static code analysis, it pinpoints different homomorphic encryption schemes for every data column.
Still, some of the demonstrated benchmarks are ten times slower than the unecrypted execution.
\SS{} avoids of complex encryption schemes, decrypts data entering enclaves and processes in plaintext.

The \textsc{Styx}~\cite{Stephen:2016:SSP:2987550.2987574} system uses partial homorphic encryption to allow for efficient stream processing in trusted cloud environments.
Interestingly, the authors of that system mention Intel{\textregistered} SGX as possible alternative to deploy stream processing systems on trusted hardware offered by untrusted/malicious cloud environments.
\SS{} offers insights on the performances of exactly this approach.

To best of our knowledge, \SS{} is the first lightweight and low-memory footprint stream processing framework that can fully execute within SGX enclaves.

As we described before, \SS{} is executing processes taking advantage of SGX enclaves inside Docker containers.
\textsc{SCONE}~\cite{pietzuch_scone:_nodate}, which is not yet openly available, is a recently introduced system that offers a secure container mechanism for Docker to leverage the SGX trusted execution support.
It proposes a generic technology to embed any C program to execute inside an SGX enclave.
Rather than generic programs, \SS{} offers support to execute a lightweight \luavm{} inside an SGX enclave and securely execute chunks of \textsc{Lua} code inside it.
In our experiments, we execute this \luavm{} inside Docker containers.
